from typing import Protocol, runtime_checkable


@runtime_checkable
class LLMProvider(Protocol):
    """
    Defines the interface for any class that can complete a prompt.

    This abstraction allows the core service to remain decoupled from the
    specific implementation of an LLM client (e.g., Ollama, OpenAI).
    """
    def complete(self, system_prompt: str, user_prompt: str) -> str:
        """
        Generates a completion based on system and user prompts.

        Args:
            system_prompt: The instruction or context for the model.
            user_prompt: The specific input to be processed (e.g., a git diff).

        Returns:
            The text generated by the language model.
        """
        ...


class MockProvider:
    """
    A mock implementation of the LLMProvider protocol for testing.

    This provider does not make any network calls. Instead, it returns a
    predictable, templated string that includes the prompts it received.
    This is useful for unit testing components that rely on an LLMProvider.
    """
    def complete(self, system_prompt: str, user_prompt: str) -> str:
        """
        Returns a hardcoded, formatted string for test verification.
        """
        return (
            "Mock Response:\n"
            f"System Prompt: {system_prompt}\n"
            f"User Prompt: {user_prompt}"
        )

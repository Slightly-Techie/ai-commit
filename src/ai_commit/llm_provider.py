from typing import Protocol


class LLMProvider(Protocol):
    """
    Defines the interface for any class that can complete a prompt.

    This abstraction allows the core service to remain decoupled from the
    specific implementation of an LLM client (e.g., Ollama, OpenAI).
    """
    def complete(self, system_prompt: str, user_prompt: str) -> str:
        """
        Generates a completion based on system and user prompts.

        Args:
            system_prompt: The instruction or context for the model.
            user_prompt: The specific input to be processed (e.g., a git diff).

        Returns:
            The text generated by the language model.
        """
        ...
